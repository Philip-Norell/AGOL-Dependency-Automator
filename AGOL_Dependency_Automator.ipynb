{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11f0b8ff-897b-4a29-b245-40b2961494ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:33: SyntaxWarning: invalid escape sequence '\\G'\n",
      "<>:33: SyntaxWarning: invalid escape sequence '\\G'\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_2912\\1926131328.py:33: SyntaxWarning: invalid escape sequence '\\G'\n",
      "  Documentation location: \"\\\\PWU-W12k07\\GIS_Files\\Tutorials\\Dependencies\\Creating Input Data for Dependency Visualizer.docx\"'''\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'AGOL Dependency Automator\\n\\nPurpose: \\n        This script is designed to automate almost all the work involved in creating a comprehensive data lineage for AGOL content.\\n    Moreoever, this script also documents feature services that are not consumed by webmaps for the purposes of data governance. \\n    Ouput data is visualized in a series of Excel sheets formatted as sortable dependency matrices. \\n\\nMethod:\\n        There are two avenues of data capture in this script.    \\n    First, it compiles a dictionary of all webmaps in AGOL and parses their related JSONs to extract the services they depend upon. \\n    Those services are then matched to a dictionary of feature services and feature classes, producing a dictionary structured like\\n    {webmap : {service : [feature classes]}}. This is then transformed into a pandas dataframe, transposed, and then written as a \\n    formatted Excel sheet. Second, the same process is performed on a dictionary of experiences, creating a dictionary strucutred as \\n    {experience : {webmap : {service : [feature classes]}}.\\n\\nInputs:\\n        This script takes inputs from two sources. The first is directly from Portal/AGOL via the ArcGIS API, and the second is a \\n    manually created document detailing which feature classes services consume. The second document must be created and maintained \\n    manually, but such maintenance will only be required infrequently due to how seldom feature classes (as well as referenced services)\\n    are added or removed from SDE. The creation process for the feature class input sheet is detailed in the documentation. \\n\\nLimitations: \\n        This script does not capture which services experiences consume directly without a webmap intermediary.\\n    To my knowledge, this is possible but may be difficult. Therefore, since our standard practice is for experiences to only\\n    consume webmaps, I didn\\'t deem this necessary. Furthermore, the orphan services sheet produced does not account for services\\n    drawn upon by solutions. \\n\\nMisc:\\n        The dictionary-building code chunks will often return error text along the lines of \"Service (ID String) does not exist.\"\\n    These are deleted services that retain their itemID but have all attributes such as title and URL erased. If the ID is plugged \\n    into a standard AGOL/Portal item URL, it will say the service is deleted or unavailable. \\n\\nDocumentation location: \"\\\\PWU-W12k07\\\\GIS_Files\\\\Tutorials\\\\Dependencies\\\\Creating Input Data for Dependency Visualizer.docx\"'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''AGOL Dependency Automator\n",
    "\n",
    "Purpose: \n",
    "        This script is designed to automate almost all the work involved in creating a comprehensive data lineage for AGOL content.\n",
    "    Moreoever, this script also documents feature services that are not consumed by webmaps for the purposes of data governance. \n",
    "    Ouput data is visualized in a series of Excel sheets formatted as sortable dependency matrices. \n",
    "\n",
    "Method:\n",
    "        There are two avenues of data capture in this script.    \n",
    "    First, it compiles a dictionary of all webmaps in AGOL and parses their related JSONs to extract the services they depend upon. \n",
    "    Those services are then matched to a dictionary of feature services and feature classes, producing a dictionary structured like\n",
    "    {webmap : {service : [feature classes]}}. This is then transformed into a pandas dataframe, transposed, and then written as a \n",
    "    formatted Excel sheet. Second, the same process is performed on a dictionary of experiences, creating a dictionary strucutred as \n",
    "    {experience : {webmap : {service : [feature classes]}}.\n",
    "\n",
    "Inputs:\n",
    "        This script takes inputs from two sources. The first is directly from Portal/AGOL via the ArcGIS API, and the second is a \n",
    "    manually created document detailing which feature classes services consume. The second document must be created and maintained \n",
    "    manually, but such maintenance will only be required infrequently due to how seldom feature classes (as well as referenced services)\n",
    "    are added or removed from SDE. The creation process for the feature class input sheet is detailed in the documentation. \n",
    "\n",
    "Limitations: \n",
    "        This script does not capture which services experiences consume directly without a webmap intermediary.\n",
    "    To my knowledge, this is possible but may be difficult. Therefore, since our standard practice is for experiences to only\n",
    "    consume webmaps, I didn't deem this necessary. Furthermore, the orphan services sheet produced does not account for services\n",
    "    drawn upon by solutions. \n",
    "\n",
    "Misc:\n",
    "        The dictionary-building code chunks will often return error text along the lines of \"Service (ID String) does not exist.\"\n",
    "    These are deleted services that retain their itemID but have all attributes such as title and URL erased. If the ID is plugged \n",
    "    into a standard AGOL/Portal item URL, it will say the service is deleted or unavailable. \n",
    "\n",
    "Documentation location: \"\\\\PWU-W12k07\\GIS_Files\\Tutorials\\Dependencies\\Creating Input Data for Dependency Visualizer.docx\"'''\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "225376c1-cb59-4469-8bce-83cff4b5920d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcgis.gis import GIS\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import datetime\n",
    "import xlsxwriter as xl\n",
    "import numpy as np\n",
    "\n",
    "date = datetime.date.today()\n",
    "formatted_date_mdy = date.strftime(\"%m_%d_%Y\")\n",
    "os.mkdir(fr\"\\\\PWU-W12k07\\GIS_Files\\Tutorials\\Dependencies\\AGOL_Dependencies_{formatted_date_mdy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29cce26e-4a65-4598-9ea5-5941594db5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to ArcGIS Online\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Imports experiences, apps and maps from AGOL and converts them into dictionaries. \n",
    "# Apps are not used in the code, but it could be adapted such that apps replace experiences.\n",
    "# Ai-assisted.\n",
    "\n",
    "ExpTitle = []\n",
    "ExpID = []\n",
    "MapTitle = []\n",
    "MapID = []\n",
    "servtitle = [] \n",
    "servid = []\n",
    "servtype = []\n",
    "servurl = []\n",
    "servowner = []\n",
    "servcreated = []\n",
    "servmod = []\n",
    "servcreated_unix = []\n",
    "servmod_unix = []\n",
    "dashtitle = []\n",
    "dashid = []\n",
    "\n",
    "portal_url = \"https://billings.maps.arcgis.com\"  \n",
    "username = \"GisAdminAcct\"\n",
    "password = \"GAdmin25@2024\"     \n",
    "\n",
    "try:\n",
    "    gis = GIS(portal_url, username, password)\n",
    "    print(f\"Successfully connected to {gis.properties.portalName}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to the portal: {e}\")\n",
    "    exit()\n",
    "\n",
    "web_exps = gis.content.search(query = \"type:Web Experience\", item_type = \"Web Experience\", max_items = 1000)\n",
    "web_maps = gis.content.search(query = \"type:Web Map\", item_type = \"Web Map\", max_items = 1000)\n",
    "feature_services = gis.content.search(query = \"type:Feature Service\", item_type = \"Feature Service\", max_items = 5000)\n",
    "map_services = gis.content.search(query = \"type:Map Service\", item_type = \"Map Service\", max_items = 5000)\n",
    "vector_services = gis.content.search(query = \"type:Vector Tile Service\", item_type = \"Vector Tile Service\", max_items = 5000)\n",
    "dashboards = gis.content.search(query = \"type:Dashboard\", item_type = \"Dashboard\", max_items = 1000)\n",
    "\n",
    "\n",
    "if web_exps:\n",
    "    for web_exp in web_exps:\n",
    "        ExpTitle.append(web_exp.title)\n",
    "        ExpID.append(web_exp.id)\n",
    "else:\n",
    "    print(\"No experiences found in the portal.\")\n",
    "\n",
    "if web_maps:\n",
    "    for web_map in web_maps:\n",
    "        MapTitle.append(web_map.title)\n",
    "        MapID.append(web_map.id)   \n",
    "            \n",
    "else:\n",
    "    print(\"No Web Maps found in the portal.\") \n",
    "\n",
    "if feature_services:\n",
    "    for service in feature_services:\n",
    "        servtitle.append(service.title)\n",
    "        servid.append(service.id)\n",
    "        servtype.append(service.type)\n",
    "        servurl.append(service.url)\n",
    "        servowner.append(service.owner)\n",
    "        servcreated_unix.append(service.created)\n",
    "        servmod_unix.append(service.modified)\n",
    "        \n",
    "if map_services:\n",
    "    for service in map_services:\n",
    "        servtitle.append(service.title)\n",
    "        servid.append(service.id)\n",
    "        servtype.append(service.type)\n",
    "        servurl.append(service.url)\n",
    "        servowner.append(service.owner)\n",
    "        servcreated_unix.append(service.created)\n",
    "        servmod_unix.append(service.modified)\n",
    "        \n",
    "if vector_services:\n",
    "    for service in vector_services:\n",
    "        servtitle.append(service.title)\n",
    "        servid.append(service.id)\n",
    "        servtype.append(service.type)\n",
    "        servurl.append(service.url)\n",
    "        servowner.append(service.owner)\n",
    "        servcreated_unix.append(service.created)\n",
    "        servmod_unix.append(service.modified)\n",
    "\n",
    "if dashboards:\n",
    "    for dashboard in dashboards:\n",
    "        dashtitle.append(dashboard.title)\n",
    "        dashid.append(dashboard.id)\n",
    "\n",
    "        \n",
    "expdict = dict(zip(ExpTitle, ExpID)) \n",
    "mapdict = dict(zip(MapTitle, MapID)) \n",
    "dashdict = dict(zip(dashtitle, dashid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d35e669b-a06b-40dd-a22d-b09fa0d182bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in servcreated_unix: # Converts unix millisecond timestamp to date\n",
    "    date_s = each / 1000\n",
    "    date = datetime.date.fromtimestamp(date_s)\n",
    "    servcreated.append(date)\n",
    "\n",
    "for each in servmod_unix:\n",
    "    date_s = each / 1000\n",
    "    date = datetime.date.fromtimestamp(date_s)\n",
    "    servmod.append(date)\n",
    "    \n",
    "\n",
    "services_list = [] \n",
    "for name, ID, typ, url, owner, created, modified in zip(servtitle, servid, servtype, servurl, servowner, servcreated, servmod):\n",
    "    string = name + \" | \" + owner + \" | \" + f'{created}' + \" | \" + f'{modified}' + \" | \" + ID + \" | \" + typ + \" | \" + url\n",
    "    services_list.append(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c526a73b-bd11-4c74-8bc0-e78edb110241",
   "metadata": {},
   "outputs": [],
   "source": [
    "dependency_df = pd.read_csv(r\"\\\\PWU-W12k07\\GIS_Files\\Tutorials\\Dependencies\\FeatureServiceFeatureClassDependencies.csv\")\n",
    "\n",
    "temp_df = dependency_df.T.values\n",
    "temp_list = []\n",
    "for each in temp_df:\n",
    "    x = []\n",
    "    for val in each:\n",
    "        if val != \"N\":\n",
    "            x.append(val)      \n",
    "    \n",
    "    temp_list.append(x)\n",
    "\n",
    "keylist = []\n",
    "vallist = []\n",
    "for each in temp_list:\n",
    "    key = each[0]\n",
    "    keylist.append(key)\n",
    "    val = each[1:]\n",
    "    vallist.append(val)\n",
    "\n",
    "fc_dict = dict(zip(keylist, vallist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b45a28b4-d53b-49f2-8842-25fce16f3b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Functions\n",
    "\n",
    "# Creates a dictionary of experiences/dashboards and webmaps. Used on the JSONs of dashboards and experiences.\n",
    "def find_web_maps(data,found_values=None): \n",
    "    if found_values is None:\n",
    "        found_values = []\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            if data.get('type') == 'WEB_MAP':\n",
    "                if 'itemId' in data:\n",
    "                    dep_item = gis.content.get(data['itemId'])\n",
    "                    if dep_item:\n",
    "                        info_str = (f\"{dep_item.title}, Item ID: {dep_item.id}\") \n",
    "                        found_values.append(info_str)\n",
    "            find_web_maps(value,found_values)\n",
    "\n",
    "    \n",
    "    return found_values\n",
    "\n",
    "def dash_find_web_maps(data,found_values=None): \n",
    "    if found_values is None:\n",
    "        found_values = []\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        if \"itemId\" in data:\n",
    "            \n",
    "            dep_id = data.get('itemId')            \n",
    "            if dep_id is not None:\n",
    "                dep_item = gis.content.get(dep_id)\n",
    "                if dep_item:\n",
    "                    info_str = info_str = (f\"{dep_item.title}, Item ID: {dep_item.id}, {dep_item.type}\")\n",
    "                    found_values.append(info_str)\n",
    "                else:\n",
    "                    print(f'Service {dep_id} does not exist')\n",
    "                    \n",
    "        for key, value in data.items():\n",
    "            dash_find_web_maps(value, found_values)\n",
    "            \n",
    "    elif isinstance(data, list): \n",
    "        for each in data:\n",
    "            dash_find_web_maps(each, found_values)\n",
    "    \n",
    "    return found_values\n",
    "\n",
    "\n",
    "# Recursively searches though map dependency JSON for item IDs and rest service URLs and creates a list of dependencies.\n",
    "# Used within a for loop of web maps.\n",
    "\n",
    "def dependency_recursion(data,found_values=None):\n",
    "    if found_values is None:\n",
    "        found_values = []\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        if 'itemId' in data:\n",
    "            dep_id = data.get('itemId')\n",
    "            dep_item = gis.content.get(dep_id)\n",
    "            if dep_item:\n",
    "                info_str = (f\"{dep_item.title} || {dep_item.id} || {dep_item.type} || {dep_item.url}\")\n",
    "                found_values.append(info_str)\n",
    "            else:\n",
    "                print(f'Service {dep_id} does not exist')\n",
    "        elif 'url' in data:\n",
    "            info_str = data.get('url')\n",
    "            if r'/image' not in info_str.lower() and r'/mapviewer' not in info_str.lower() and not re.fullmatch(r'[\\w\\W]{32,38}', info_str):\n",
    "                found_values.append(info_str)\n",
    "            \n",
    "        for key, value in data.items():\n",
    "            dependency_recursion(value, found_values)\n",
    "            \n",
    "    elif isinstance(data, list): \n",
    "        for each in data:\n",
    "            dependency_recursion(each, found_values)\n",
    "    \n",
    "    return found_values\n",
    "    \n",
    "# AI-created alphabet generator function\n",
    "def make_alphabet(n):\n",
    "    labels = []\n",
    "    while len(labels) < n:\n",
    "        num = len(labels)\n",
    "        label = \"\"\n",
    "        while True:\n",
    "            num, rem = divmod(num, 26)\n",
    "            label = chr(65 + rem) + label\n",
    "            if num == 0:\n",
    "                break\n",
    "            num -= 1\n",
    "        labels.append(label)\n",
    "    return labels\n",
    "\n",
    "# Xlsxwriter formatting function\n",
    "def create_new_sheet(writer_object, dataframe, sheet_title, index_str):\n",
    "    dataframe = dataframe.fillna(\"\")\n",
    "    dataframe.to_excel(writer, sheet_name = sheet_title)\n",
    "    sheet_id = writer.sheets[sheet_title]\n",
    "    \n",
    "    headers_list = []\n",
    "    for each in dataframe.columns:\n",
    "        headers = {'header' : each}\n",
    "        headers_list.append(headers)    \n",
    "    headers_list[0:0] = [{'header' : index_str}]\n",
    "\n",
    "    alphabet = make_alphabet(len(headers_list))\n",
    "    rowcount = dataframe.shape[0] + 1\n",
    "\n",
    "    sheet_id.add_table(f'A1:{alphabet[-1]}{rowcount}', {'columns' : headers_list})\n",
    "\n",
    "    return sheet_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d3165087-3af9-4d91-bd50-f289e5febae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts mapdict's keys into a better format for later use\n",
    "templist = []\n",
    "mapdict2 = {}\n",
    "for each in mapdict:\n",
    "    deptemp = gis.content.get(mapdict[each])\n",
    "    infostrtemp = (f\"{deptemp.title}, Item ID: {deptemp.id}\")\n",
    "    templist.append(infostrtemp)\n",
    "    mapdict2[infostrtemp] = mapdict[each]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eacfc3f0-7c60-4a6f-a3a3-71f6e39e7888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Service 7c26778aeb7a49cbaeb39288af899117 does not exist\n",
      "Service ed17a08d5d8b4a5d9ca29c02449ac1d5 does not exist\n",
      "Service ed17a08d5d8b4a5d9ca29c02449ac1d5 does not exist\n",
      "Service ed17a08d5d8b4a5d9ca29c02449ac1d5 does not exist\n",
      "Service f45ec5d48dfd458dafcedce5ee97d61d does not exist\n",
      "Service 33632d6ab9cd4fd8b6fb09d42cf2420f does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service 03a50e6d46f3411184f701695e3decc2 does not exist\n",
      "US Population Change, Item ID: e634e840f62d49d18c14938926ac6041 You do not have permissions to access this resource or perform this operation.\n",
      "(Error Code: 403)\n",
      "Service 56e9dd833fbf4c9dae3cbfee575c7cb6 does not exist\n",
      "Service 33632d6ab9cd4fd8b6fb09d42cf2420f does not exist\n",
      "Service 7c26778aeb7a49cbaeb39288af899117 does not exist\n",
      "Service ed17a08d5d8b4a5d9ca29c02449ac1d5 does not exist\n",
      "Service ed17a08d5d8b4a5d9ca29c02449ac1d5 does not exist\n",
      "Service f45ec5d48dfd458dafcedce5ee97d61d does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service b999b316d1b0425383f161ff0e21142d does not exist\n",
      "Service 6df8c73e09624e028c5840a1303d5062 does not exist\n",
      "Service 6df8c73e09624e028c5840a1303d5062 does not exist\n",
      "Service 6df8c73e09624e028c5840a1303d5062 does not exist\n",
      "Service 6df8c73e09624e028c5840a1303d5062 does not exist\n",
      "Service 6df8c73e09624e028c5840a1303d5062 does not exist\n",
      "Service 6df8c73e09624e028c5840a1303d5062 does not exist\n",
      "Service 6df8c73e09624e028c5840a1303d5062 does not exist\n",
      "Service 6df8c73e09624e028c5840a1303d5062 does not exist\n",
      "Service 6df8c73e09624e028c5840a1303d5062 does not exist\n",
      "Service 6df8c73e09624e028c5840a1303d5062 does not exist\n",
      "Service 6df8c73e09624e028c5840a1303d5062 does not exist\n",
      "Service 7c26778aeb7a49cbaeb39288af899117 does not exist\n",
      "Service ed17a08d5d8b4a5d9ca29c02449ac1d5 does not exist\n",
      "Service ed17a08d5d8b4a5d9ca29c02449ac1d5 does not exist\n",
      "Service f45ec5d48dfd458dafcedce5ee97d61d does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service d1739d21274847e8a2d25c90100375c3 does not exist\n",
      "Service 7326058bdcc54002a5c13d02cb41b3ea does not exist\n",
      "Service 7c26778aeb7a49cbaeb39288af899117 does not exist\n",
      "Service ed17a08d5d8b4a5d9ca29c02449ac1d5 does not exist\n",
      "Service ed17a08d5d8b4a5d9ca29c02449ac1d5 does not exist\n",
      "Service f45ec5d48dfd458dafcedce5ee97d61d does not exist\n",
      "Service 7c26778aeb7a49cbaeb39288af899117 does not exist\n",
      "Service ed17a08d5d8b4a5d9ca29c02449ac1d5 does not exist\n",
      "Service ed17a08d5d8b4a5d9ca29c02449ac1d5 does not exist\n",
      "Service f45ec5d48dfd458dafcedce5ee97d61d does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service b999b316d1b0425383f161ff0e21142d does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service b999b316d1b0425383f161ff0e21142d does not exist\n",
      "Service b059f0ac7d2b4ee8afb4b03105b1e6d1 does not exist\n",
      "Service b059f0ac7d2b4ee8afb4b03105b1e6d1 does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service 7c26778aeb7a49cbaeb39288af899117 does not exist\n",
      "Service ed17a08d5d8b4a5d9ca29c02449ac1d5 does not exist\n",
      "Service ed17a08d5d8b4a5d9ca29c02449ac1d5 does not exist\n",
      "Service f45ec5d48dfd458dafcedce5ee97d61d does not exist\n"
     ]
    }
   ],
   "source": [
    "map_dependency_dict = {}\n",
    "for key in mapdict2:\n",
    "    innermost_dict = {}\n",
    "    try:\n",
    "        mapItem = gis.content.get(mapdict2[key]) #finds webmap associated with the id value in mapdict.\n",
    "        dependencies = mapItem.get_data(try_json = True)['operationalLayers'] #returns a dictionary with details on supporting services. try_json is optional but may help convert the data to a dictionary.\n",
    "        dep_info_list = []\n",
    "        \n",
    "        dep_info_list = dependency_recursion(dependencies) #Pulls supporting services out of dependency JSON and adds to list\n",
    "                    \n",
    "        for each in dep_info_list:\n",
    "            match_found = False\n",
    "            for x, y in fc_dict.items():\n",
    "                if x in each:\n",
    "                    innermost_dict[each] = y\n",
    "                    match_found = True\n",
    "                    break\n",
    "                if not match_found:\n",
    "                    innermost_dict[each] = [\"This Service is Hosted on AGOL or is a Raster Image\"]\n",
    "        \n",
    "        map_dependency_dict[key] = innermost_dict #writes keys and values to empty dictionary.\n",
    "    except Exception as e:\n",
    "        print(f'{key} {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8a7674cd-06ee-4575-81db-f84169367149",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_dependency_dict = {}\n",
    "\n",
    "for key in expdict:\n",
    "    try:\n",
    "        experience = gis.content.get(expdict[key])\n",
    "        func_in = experience.get_data()\n",
    "        final = find_web_maps(func_in)\n",
    "        experience_dependency_dict[key] = final\n",
    "    except Exception as e:\n",
    "        print(f'{key}{e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0bcaf72c-ff50-4814-8c37-8faf2a67ba04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untitled experience 1 You do not have permissions to access this resource or perform this operation.\n",
      "(Error Code: 403)\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service 7326058bdcc54002a5c13d02cb41b3ea does not exist\n",
      "Service 7326058bdcc54002a5c13d02cb41b3ea does not exist\n",
      "Service 7326058bdcc54002a5c13d02cb41b3ea does not exist\n",
      "Service 7326058bdcc54002a5c13d02cb41b3ea does not exist\n",
      "Service 7326058bdcc54002a5c13d02cb41b3ea does not exist\n",
      "Service 359b82da4d1342e58190fab4d814530b does not exist\n",
      "Service 359b82da4d1342e58190fab4d814530b does not exist\n",
      "Service 359b82da4d1342e58190fab4d814530b does not exist\n",
      "Service 359b82da4d1342e58190fab4d814530b does not exist\n",
      "Service 359b82da4d1342e58190fab4d814530b does not exist\n",
      "Service 359b82da4d1342e58190fab4d814530b does not exist\n",
      "Service 359b82da4d1342e58190fab4d814530b does not exist\n",
      "Service 359b82da4d1342e58190fab4d814530b does not exist\n",
      "Service 359b82da4d1342e58190fab4d814530b does not exist\n",
      "Service 359b82da4d1342e58190fab4d814530b does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service b999b316d1b0425383f161ff0e21142d does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service b999b316d1b0425383f161ff0e21142d does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service b999b316d1b0425383f161ff0e21142d does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service b999b316d1b0425383f161ff0e21142d does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service b999b316d1b0425383f161ff0e21142d does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service b999b316d1b0425383f161ff0e21142d does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service b999b316d1b0425383f161ff0e21142d does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service b999b316d1b0425383f161ff0e21142d does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service b999b316d1b0425383f161ff0e21142d does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service b999b316d1b0425383f161ff0e21142d does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service b999b316d1b0425383f161ff0e21142d does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service b999b316d1b0425383f161ff0e21142d does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service b999b316d1b0425383f161ff0e21142d does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service b999b316d1b0425383f161ff0e21142d does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service b999b316d1b0425383f161ff0e21142d does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service b999b316d1b0425383f161ff0e21142d does not exist\n",
      "Service 9387cf9b99c844c4a56f59417e5223b4 does not exist\n",
      "Service b999b316d1b0425383f161ff0e21142d does not exist\n"
     ]
    }
   ],
   "source": [
    "# Creates a nested dictionary detailing all dependency levels.\n",
    "# The dictionary is formatted as follows: {Experience: {Web Map: {Service: [Feature Class]}}}\n",
    "\n",
    "\n",
    "exp_dependency_dict = {}\n",
    "for key in experience_dependency_dict: #Looping over experiences\n",
    "    inner_dict = {}\n",
    "\n",
    "    \n",
    "    #Finds the dependencies of each webmap associated with each experience    \n",
    "    try:\n",
    "        for webmapval in experience_dependency_dict[key]: #Looping over webmaps corresponding to each experience\n",
    "            innermost_dict = {}\n",
    "            match = re.search(r'ID:\\s*([\\w]+)', webmapval, re.IGNORECASE) #Uses regex matching to extract webmap itemid from the dictionary value.\n",
    "            idtext = match.group(1)\n",
    "            mapItem = gis.content.get(idtext) #Finds webmap associated with the id value\n",
    "            dependencies = mapItem.get_data(try_json = True)['operationalLayers'] #returns a dictionary with details on supporting services. try_json is optional but may help convert the data to a dictionary.\n",
    "        \n",
    "            for depinfo in dependencies: #Looping through the dependency JSON for a single web map\n",
    "                dep_info_list = dependency_recursion(depinfo) #Pulls supporting services out of dependency JSON and adds to list\n",
    "            \n",
    "\n",
    "                # Matches the service feature class dependencies to the feature class dependency dict made from the input csv.\n",
    "                # For every service that matches a url in the csv, the supporting feature classes are added as values.\n",
    "                # This creates the innermost dictionary in the nested dictionary that will be inputted into pyvis.\n",
    "\n",
    "                for each in dep_info_list: #Looping through the services associated with a single web map\n",
    "                    match_found = False\n",
    "                    for x, y in fc_dict.items(): \n",
    "                        if x in each:\n",
    "                            innermost_dict[each] = y\n",
    "                            match_found = True\n",
    "                            break\n",
    "                    if not match_found:\n",
    "                        innermost_dict[each] = [\"This Service is Hosted on AGOL or is a Raster Image\"]\n",
    "                                                                            \n",
    "            inner_dict[f\"{mapItem.title}, Item ID: {mapItem.id}\"] = innermost_dict\n",
    "            \n",
    "        exp_dependency_dict[key] = inner_dict #writes keys and values to empty dictionary.\n",
    "    except Exception as e:\n",
    "        print(f'{key} {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3f82c4a1-ab86-41c8-bcb8-ca29bf952aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accounting for edge cases such as maps with no services, experiences with no maps, etc. \n",
    "\n",
    "for webmap, service in map_dependency_dict.items():\n",
    "    if not service:        \n",
    "        map_dependency_dict[webmap] = {\"This Webmap has no Supporting Services\": [\"No Services Therefore no FCs\"]}\n",
    "for exp, webmap in exp_dependency_dict.items():\n",
    "    if not webmap:\n",
    "        exp_dependency_dict[exp] = {\"This Experience has no Supporting Services\" : {\"Likely no Webmap, Likely no Services\": [\"Likely no Services, Likely no FCs\"]}}\n",
    "for exp, webmap in exp_dependency_dict.items():       \n",
    "    for wmap, service in webmap.items():\n",
    "        if not service: \n",
    "            webmap[wmap] = {\"This Webmap has no Supporting Services\": [\"No Services Therefore no FCs\"]}\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "afdad564-9667-4df6-ab65-e076378aa70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Service 886981f7-3d6b-4cab-aee2-5a905c54df47 does not exist\n",
      "Service e8d81e2a-86aa-4435-bab6-f7d7eda13457 does not exist\n",
      "Service 3efab53cc9ea485085f74747af7f079a does not exist\n",
      "Service 886981f7-3d6b-4cab-aee2-5a905c54df47 does not exist\n",
      "Service e8d81e2a-86aa-4435-bab6-f7d7eda13457 does not exist\n",
      "Service 3efab53cc9ea485085f74747af7f079a does not exist\n",
      "Service 4af68b42-c6ab-4aaa-a022-57cbe36e6cbc does not exist\n",
      "Service 4af68b42-c6ab-4aaa-a022-57cbe36e6cbc does not exist\n",
      "Service ae384b06-dec9-4758-bafe-01d9d79a4a1f does not exist\n",
      "Service 54da2a15-0acc-4cae-8d85-ab8aaef68c21 does not exist\n",
      "Service 081d58dd2620479d8031b1089c5a024e does not exist\n",
      "Service 081d58dd2620479d8031b1089c5a024e does not exist\n",
      "Service 081d58dd2620479d8031b1089c5a024e does not exist\n",
      "Service ae384b06-dec9-4758-bafe-01d9d79a4a1f does not exist\n",
      "Service 54da2a15-0acc-4cae-8d85-ab8aaef68c21 does not exist\n",
      "Service 081d58dd2620479d8031b1089c5a024e does not exist\n",
      "Service 54da2a15-0acc-4cae-8d85-ab8aaef68c21 does not exist\n",
      "Service 081d58dd2620479d8031b1089c5a024e does not exist\n",
      "Service 081d58dd2620479d8031b1089c5a024e does not exist\n",
      "Service 081d58dd2620479d8031b1089c5a024e does not exist\n",
      "Service 081d58dd2620479d8031b1089c5a024e does not exist\n",
      "Service 081d58dd2620479d8031b1089c5a024e does not exist\n",
      "Service 081d58dd2620479d8031b1089c5a024e does not exist\n",
      "Service 4c132d54-8229-4921-9fde-b95fc27d60d9 does not exist\n",
      "Service 77a07dcfb6e947c093fc2bba3c375fc2 does not exist\n",
      "Service 4c132d54-8229-4921-9fde-b95fc27d60d9 does not exist\n",
      "Service 4c132d54-8229-4921-9fde-b95fc27d60d9 does not exist\n",
      "Service 77a07dcfb6e947c093fc2bba3c375fc2 does not exist\n",
      "Service 4c132d54-8229-4921-9fde-b95fc27d60d9 does not exist\n",
      "Service 4c132d54-8229-4921-9fde-b95fc27d60d9 does not exist\n",
      "Service 4c132d54-8229-4921-9fde-b95fc27d60d9 does not exist\n",
      "Service 77a07dcfb6e947c093fc2bba3c375fc2 does not exist\n",
      "Service 77a07dcfb6e947c093fc2bba3c375fc2 does not exist\n",
      "Service f395068006db4c19b4e533024701adc5 does not exist\n",
      "Service 61d987d70c604fcd8bb2f4ccaa9b8974 does not exist\n",
      "Service 61d987d70c604fcd8bb2f4ccaa9b8974 does not exist\n",
      "Service 61d987d70c604fcd8bb2f4ccaa9b8974 does not exist\n",
      "Service 61d987d70c604fcd8bb2f4ccaa9b8974 does not exist\n"
     ]
    }
   ],
   "source": [
    "# Creation of dashboard dependency dictionaries. Splits dependencies into flat and heiarchical structures e.g. {dashboard : service} and\n",
    "# {dashboard : {webmap: {service}}}\n",
    "\n",
    "dashboard_map_dependency_dict = {}\n",
    "dashboard_service_dependency_dict = {}\n",
    "\n",
    "\n",
    "for key in dashdict:\n",
    "    temp_map_list = []\n",
    "    temp_service_list = []\n",
    "    try:\n",
    "        dashboard = gis.content.get(dashdict[key])\n",
    "        func_in = dashboard.get_data()\n",
    "        final = dash_find_web_maps(func_in)\n",
    "        for each in final:\n",
    "            if \"Web Map\" in each:\n",
    "                temp_map_list.append(each)\n",
    "                dashboard_map_dependency_dict[key] = temp_map_list\n",
    "            else: \n",
    "                temp_service_list.append(each)\n",
    "                dashboard_service_dependency_dict[key] = temp_service_list\n",
    "    except Exception as e:\n",
    "        print(f'{key}{e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d8d5b058-6b67-4121-b67d-60ac041f1b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Snowplow Dashboard Base Exercise 2 - BJ': ['Snow Response Map, Item ID: 5da6bcd872124b59b45d36bfa9c89095, Web Map'],\n",
       " 'Engineering Dashboard': ['Engineering Map_RO, Item ID: a1356197bc774e788d7a03454c476b9f, Web Map'],\n",
       " 'Parks Classification Map Dashboard': ['Park Classification Map, Item ID: ec035b4a2a33478ab175194d9dea10ef, Web Map'],\n",
       " 'Snowplow Dashboard Base - BJ': ['Snow Response Map, Item ID: 5da6bcd872124b59b45d36bfa9c89095, Web Map'],\n",
       " 'Sober Housing Dashboard': ['Sober Housing Web Map, Item ID: 99d2853dce8446bc9c7d17d3323abc58, Web Map'],\n",
       " 'Citizen Problem Dashboard': ['Citizen Problem Dashboard, Item ID: fae2292874ba46ad939548bdb74021d8, Web Map',\n",
       "  'Citizen Problem Dashboard, Item ID: fae2292874ba46ad939548bdb74021d8, Web Map',\n",
       "  'Citizen Problem Dashboard, Item ID: fae2292874ba46ad939548bdb74021d8, Web Map',\n",
       "  'Citizen Problem Dashboard, Item ID: fae2292874ba46ad939548bdb74021d8, Web Map',\n",
       "  'Citizen Problem Dashboard, Item ID: fae2292874ba46ad939548bdb74021d8, Web Map',\n",
       "  'Citizen Problem Dashboard, Item ID: fae2292874ba46ad939548bdb74021d8, Web Map',\n",
       "  'Citizen Problem Dashboard, Item ID: fae2292874ba46ad939548bdb74021d8, Web Map',\n",
       "  'Citizen Problem Dashboard, Item ID: fae2292874ba46ad939548bdb74021d8, Web Map',\n",
       "  'Citizen Problem Dashboard, Item ID: fae2292874ba46ad939548bdb74021d8, Web Map',\n",
       "  'Citizen Problem Dashboard, Item ID: fae2292874ba46ad939548bdb74021d8, Web Map',\n",
       "  'Citizen Problem Survey, Item ID: 023e93827d354abd93df4ae94e8430c9, Web Map',\n",
       "  'Citizen Problem Survey, Item ID: 023e93827d354abd93df4ae94e8430c9, Web Map',\n",
       "  'Citizen Problem Survey, Item ID: 023e93827d354abd93df4ae94e8430c9, Web Map',\n",
       "  'Citizen Problem Survey, Item ID: 023e93827d354abd93df4ae94e8430c9, Web Map',\n",
       "  'Citizen Problem Survey, Item ID: 023e93827d354abd93df4ae94e8430c9, Web Map',\n",
       "  'Citizen Problem Survey, Item ID: 023e93827d354abd93df4ae94e8430c9, Web Map',\n",
       "  'Citizen Problem Survey, Item ID: 023e93827d354abd93df4ae94e8430c9, Web Map',\n",
       "  'Citizen Problem Dashboard, Item ID: fae2292874ba46ad939548bdb74021d8, Web Map',\n",
       "  'Citizen Problem Dashboard, Item ID: fae2292874ba46ad939548bdb74021d8, Web Map',\n",
       "  'Citizen Problem Dashboard, Item ID: fae2292874ba46ad939548bdb74021d8, Web Map'],\n",
       " 'BPD Offenses DB': ['BPDOffensesMap, Item ID: abf0a2cb62d04c288e0faaf7af2f690e, Web Map',\n",
       "  'BPDOffensesMap, Item ID: abf0a2cb62d04c288e0faaf7af2f690e, Web Map',\n",
       "  'BPDOffensesMap, Item ID: abf0a2cb62d04c288e0faaf7af2f690e, Web Map',\n",
       "  'BPDOffensesMap, Item ID: abf0a2cb62d04c288e0faaf7af2f690e, Web Map',\n",
       "  'BPDOffensesMap, Item ID: abf0a2cb62d04c288e0faaf7af2f690e, Web Map',\n",
       "  'BPDOffensesMap, Item ID: abf0a2cb62d04c288e0faaf7af2f690e, Web Map',\n",
       "  'BPDOffensesMap, Item ID: abf0a2cb62d04c288e0faaf7af2f690e, Web Map'],\n",
       " 'Billings Capital Project Dashboard (copy)': ['Capital Project Dashboard, Item ID: 1157014d0e5e476a891052f2e4b57ce4, Web Map'],\n",
       " 'Demo Crime Dashboard - Interactive': ['Philadelphia Crime Map, Item ID: 7dd95c7265bd40cba1fd36626f43c5dc, Web Map'],\n",
       " 'Tree Dashboard': ['Tree Dashboard, Item ID: 1e0f809a127d4ce7bbff2d51ad4244dc, Web Map',\n",
       "  'Tree Dashboard, Item ID: 1e0f809a127d4ce7bbff2d51ad4244dc, Web Map',\n",
       "  'Tree Dashboard, Item ID: 1e0f809a127d4ce7bbff2d51ad4244dc, Web Map',\n",
       "  'Tree Dashboard, Item ID: 1e0f809a127d4ce7bbff2d51ad4244dc, Web Map',\n",
       "  'Tree Dashboard, Item ID: 1e0f809a127d4ce7bbff2d51ad4244dc, Web Map',\n",
       "  'Tree Dashboard, Item ID: 1e0f809a127d4ce7bbff2d51ad4244dc, Web Map',\n",
       "  'Tree Dashboard, Item ID: 1e0f809a127d4ce7bbff2d51ad4244dc, Web Map',\n",
       "  'Tree Dashboard, Item ID: 1e0f809a127d4ce7bbff2d51ad4244dc, Web Map',\n",
       "  'Tree Dashboard, Item ID: 1e0f809a127d4ce7bbff2d51ad4244dc, Web Map',\n",
       "  'Tree Dashboard, Item ID: 1e0f809a127d4ce7bbff2d51ad4244dc, Web Map',\n",
       "  'Tree Dashboard, Item ID: 1e0f809a127d4ce7bbff2d51ad4244dc, Web Map',\n",
       "  'Tree Dashboard, Item ID: 1e0f809a127d4ce7bbff2d51ad4244dc, Web Map',\n",
       "  'Tree Dashboard, Item ID: 1e0f809a127d4ce7bbff2d51ad4244dc, Web Map',\n",
       "  'Tree Dashboard, Item ID: 1e0f809a127d4ce7bbff2d51ad4244dc, Web Map',\n",
       "  'Tree Dashboard, Item ID: 1e0f809a127d4ce7bbff2d51ad4244dc, Web Map',\n",
       "  'Tree Dashboard, Item ID: 1e0f809a127d4ce7bbff2d51ad4244dc, Web Map',\n",
       "  'Tree Dashboard, Item ID: 1e0f809a127d4ce7bbff2d51ad4244dc, Web Map',\n",
       "  'Tree Dashboard, Item ID: 1e0f809a127d4ce7bbff2d51ad4244dc, Web Map',\n",
       "  'Tree Dashboard, Item ID: 1e0f809a127d4ce7bbff2d51ad4244dc, Web Map',\n",
       "  'Tree Dashboard, Item ID: 1e0f809a127d4ce7bbff2d51ad4244dc, Web Map',\n",
       "  'Tree Dashboard, Item ID: 1e0f809a127d4ce7bbff2d51ad4244dc, Web Map',\n",
       "  'Tree Dashboard, Item ID: 1e0f809a127d4ce7bbff2d51ad4244dc, Web Map',\n",
       "  'Tree Dashboard, Item ID: 1e0f809a127d4ce7bbff2d51ad4244dc, Web Map',\n",
       "  'Tree Dashboard, Item ID: 1e0f809a127d4ce7bbff2d51ad4244dc, Web Map',\n",
       "  'Tree Dashboard, Item ID: 1e0f809a127d4ce7bbff2d51ad4244dc, Web Map',\n",
       "  'Tree Dashboard, Item ID: 1e0f809a127d4ce7bbff2d51ad4244dc, Web Map',\n",
       "  'Tree Dashboard, Item ID: 1e0f809a127d4ce7bbff2d51ad4244dc, Web Map',\n",
       "  'Tree Dashboard, Item ID: 1e0f809a127d4ce7bbff2d51ad4244dc, Web Map',\n",
       "  'Tree Dashboard, Item ID: 1e0f809a127d4ce7bbff2d51ad4244dc, Web Map',\n",
       "  'Tree Dashboard, Item ID: 1e0f809a127d4ce7bbff2d51ad4244dc, Web Map'],\n",
       " 'CFS Analysis Dashboard': ['Buildings CFS, Item ID: 5088907de99f4626ae3aee4b7616cb1d, Web Map',\n",
       "  'Buildings CFS, Item ID: 5088907de99f4626ae3aee4b7616cb1d, Web Map',\n",
       "  'Buildings CFS, Item ID: 5088907de99f4626ae3aee4b7616cb1d, Web Map',\n",
       "  'Buildings CFS, Item ID: 5088907de99f4626ae3aee4b7616cb1d, Web Map',\n",
       "  'Buildings CFS, Item ID: 5088907de99f4626ae3aee4b7616cb1d, Web Map',\n",
       "  'Buildings CFS, Item ID: 5088907de99f4626ae3aee4b7616cb1d, Web Map',\n",
       "  'Buildings CFS, Item ID: 5088907de99f4626ae3aee4b7616cb1d, Web Map',\n",
       "  'Buildings CFS, Item ID: 5088907de99f4626ae3aee4b7616cb1d, Web Map',\n",
       "  'Buildings CFS, Item ID: 5088907de99f4626ae3aee4b7616cb1d, Web Map',\n",
       "  'Buildings CFS, Item ID: 5088907de99f4626ae3aee4b7616cb1d, Web Map'],\n",
       " 'Billings Capital Project Dashboard': ['Capital Project Dashboard, Item ID: 1157014d0e5e476a891052f2e4b57ce4, Web Map'],\n",
       " 'PSN Overview Dashboard': ['PSN Data Map, Item ID: 7c2d2c9b224d4691997402ea3faeed2d, Web Map'],\n",
       " 'OLD - Billings MPO LRTP Projects Dashboard Map': ['Billings MPO LRTP Projects Dashboard Map, Item ID: 87767048e20c48328d7174baad1a51ad, Web Map',\n",
       "  'Billings MPO LRTP Projects Dashboard Map, Item ID: 87767048e20c48328d7174baad1a51ad, Web Map',\n",
       "  'Billings MPO LRTP Projects Dashboard Map, Item ID: 87767048e20c48328d7174baad1a51ad, Web Map',\n",
       "  'Billings MPO LRTP Projects Dashboard Map, Item ID: 87767048e20c48328d7174baad1a51ad, Web Map',\n",
       "  'Billings MPO LRTP Projects Dashboard Map, Item ID: 87767048e20c48328d7174baad1a51ad, Web Map',\n",
       "  'Billings MPO LRTP Projects Dashboard Map, Item ID: 87767048e20c48328d7174baad1a51ad, Web Map',\n",
       "  'Billings MPO LRTP Projects Dashboard Map, Item ID: 87767048e20c48328d7174baad1a51ad, Web Map',\n",
       "  'Billings MPO LRTP Projects Dashboard Map, Item ID: 87767048e20c48328d7174baad1a51ad, Web Map',\n",
       "  'Billings MPO LRTP Projects Dashboard Map, Item ID: 87767048e20c48328d7174baad1a51ad, Web Map'],\n",
       " 'Capital Project Dashboard (new)': ['Capital Project Dashboard, Item ID: 1157014d0e5e476a891052f2e4b57ce4, Web Map'],\n",
       " 'City of Billings- Solid Waste Cleanup': ['Public Solid Waste Cleanup Web Map, Item ID: 72b950d83f494fe39f1e9b0dfd6ecfca, Web Map'],\n",
       " 'PSN Firearms Dashboard': ['Firearm Crime Map Jan-April 2023, Item ID: 7c44c6e3fc2c486e8c53b4fe87f4523a, Web Map',\n",
       "  'Firearm Crime Map Jan-April 2023, Item ID: 7c44c6e3fc2c486e8c53b4fe87f4523a, Web Map',\n",
       "  'Firearm Crime Map Jan-April 2023, Item ID: 7c44c6e3fc2c486e8c53b4fe87f4523a, Web Map',\n",
       "  'Firearm Crime Map Jan-April 2023, Item ID: 7c44c6e3fc2c486e8c53b4fe87f4523a, Web Map',\n",
       "  'Firearm Crime Map Jan-April 2023, Item ID: 7c44c6e3fc2c486e8c53b4fe87f4523a, Web Map',\n",
       "  'Firearm Crime Map Jan-April 2023, Item ID: 7c44c6e3fc2c486e8c53b4fe87f4523a, Web Map',\n",
       "  'Firearm Crime Map Jan-April 2023, Item ID: 7c44c6e3fc2c486e8c53b4fe87f4523a, Web Map',\n",
       "  'Firearm Crime Map Jan-April 2023, Item ID: 7c44c6e3fc2c486e8c53b4fe87f4523a, Web Map',\n",
       "  'Firearm Crime Map Jan-April 2023, Item ID: 7c44c6e3fc2c486e8c53b4fe87f4523a, Web Map',\n",
       "  'Firearm Crime Map Jan-April 2023, Item ID: 7c44c6e3fc2c486e8c53b4fe87f4523a, Web Map',\n",
       "  'Firearm Crime Map Jan-April 2023, Item ID: 7c44c6e3fc2c486e8c53b4fe87f4523a, Web Map',\n",
       "  'Firearm Crime Map Jan-April 2023, Item ID: 7c44c6e3fc2c486e8c53b4fe87f4523a, Web Map',\n",
       "  'Firearm Crime Map Jan-April 2023, Item ID: 7c44c6e3fc2c486e8c53b4fe87f4523a, Web Map',\n",
       "  'Firearm Crime Map Jan-April 2023, Item ID: 7c44c6e3fc2c486e8c53b4fe87f4523a, Web Map',\n",
       "  'Firearm Crime Map Jan-April 2023, Item ID: 7c44c6e3fc2c486e8c53b4fe87f4523a, Web Map',\n",
       "  'Firearm Crime Map Jan-April 2023, Item ID: 7c44c6e3fc2c486e8c53b4fe87f4523a, Web Map',\n",
       "  'Firearm Crime Map Jan-April 2023, Item ID: 7c44c6e3fc2c486e8c53b4fe87f4523a, Web Map',\n",
       "  'Firearm Crime Map Jan-April 2023, Item ID: 7c44c6e3fc2c486e8c53b4fe87f4523a, Web Map',\n",
       "  'Firearm Crime Map Jan-April 2023, Item ID: 7c44c6e3fc2c486e8c53b4fe87f4523a, Web Map',\n",
       "  'Firearm Crime Map Jan-April 2023, Item ID: 7c44c6e3fc2c486e8c53b4fe87f4523a, Web Map',\n",
       "  'Firearm Crime Map Jan-April 2023, Item ID: 7c44c6e3fc2c486e8c53b4fe87f4523a, Web Map',\n",
       "  'Firearm Crime Map Jan-April 2023, Item ID: 7c44c6e3fc2c486e8c53b4fe87f4523a, Web Map',\n",
       "  'Firearm Crime Map Jan-April 2023, Item ID: 7c44c6e3fc2c486e8c53b4fe87f4523a, Web Map'],\n",
       " 'Environmental Affairs Backflow Dashboard': ['Backflow Inspection Map, Item ID: 5975810699c24b9d9d34dd24d87702ed, Web Map'],\n",
       " 'Multi-Use Trails Map JG': ['Multi-Use Trails Map JG, Item ID: 44815f4ff20d433dbd612d7b41c14977, Web Map'],\n",
       " 'Billings Capital Project Dashboard v2': ['Billings Capital Project Dashboard v2, Item ID: 707165ef23b2491ab2b84943ee59fe82, Web Map',\n",
       "  'Billings Capital Project Dashboard v2, Item ID: 707165ef23b2491ab2b84943ee59fe82, Web Map',\n",
       "  'Billings Capital Project Dashboard v2, Item ID: 707165ef23b2491ab2b84943ee59fe82, Web Map',\n",
       "  'Billings Capital Project Dashboard v2, Item ID: 707165ef23b2491ab2b84943ee59fe82, Web Map',\n",
       "  'Billings Capital Project Dashboard v2, Item ID: 707165ef23b2491ab2b84943ee59fe82, Web Map',\n",
       "  'Billings Capital Project Dashboard v2, Item ID: 707165ef23b2491ab2b84943ee59fe82, Web Map',\n",
       "  'Billings Capital Project Dashboard v2, Item ID: 707165ef23b2491ab2b84943ee59fe82, Web Map',\n",
       "  'Billings Capital Project Dashboard v2, Item ID: 707165ef23b2491ab2b84943ee59fe82, Web Map',\n",
       "  'Billings Capital Project Dashboard v2, Item ID: 707165ef23b2491ab2b84943ee59fe82, Web Map',\n",
       "  'Billings Capital Project Dashboard v2, Item ID: 707165ef23b2491ab2b84943ee59fe82, Web Map',\n",
       "  'Billings Capital Project Dashboard v2, Item ID: 707165ef23b2491ab2b84943ee59fe82, Web Map',\n",
       "  'Billings Capital Project Dashboard v2, Item ID: 707165ef23b2491ab2b84943ee59fe82, Web Map'],\n",
       " 'City of Billings - Street Sweeping': ['Billings Street Sweeping Web Map Public, Item ID: 75562589a9ed41bc9af8a733f95c9852, Web Map',\n",
       "  'Billings Street Sweeping Web Map Public, Item ID: 75562589a9ed41bc9af8a733f95c9852, Web Map',\n",
       "  'Billings Street Sweeping Web Map Public, Item ID: 75562589a9ed41bc9af8a733f95c9852, Web Map'],\n",
       " 'TF Incidents DB': ['TF Incidents Map, Item ID: a1cb4b9acbb6413db62ca9cfa5d45c5a, Web Map',\n",
       "  'TF Incidents Map, Item ID: a1cb4b9acbb6413db62ca9cfa5d45c5a, Web Map'],\n",
       " 'General Fund Parks Map Dashboard': ['General Fund Parks, Item ID: 1dfb4ab647f244de804d091c36787b8b, Web Map'],\n",
       " 'TF Areas Dashboard': ['TF Area Offenses, Item ID: d96461b44d5a443fac7788bfcb305d0c, Web Map',\n",
       "  'TF Area Offenses, Item ID: d96461b44d5a443fac7788bfcb305d0c, Web Map',\n",
       "  'TF Area Offenses, Item ID: d96461b44d5a443fac7788bfcb305d0c, Web Map',\n",
       "  'TF Area Offenses, Item ID: d96461b44d5a443fac7788bfcb305d0c, Web Map',\n",
       "  'TF Area Offenses, Item ID: d96461b44d5a443fac7788bfcb305d0c, Web Map',\n",
       "  'TF Area Offenses, Item ID: d96461b44d5a443fac7788bfcb305d0c, Web Map'],\n",
       " 'Citizen Problem Explorer': ['Citizen Problem Explorer, Item ID: 9d77d6608c6b4ae5a9be638df2b2fff4, Web Map',\n",
       "  'Citizen Problem Explorer, Item ID: 9d77d6608c6b4ae5a9be638df2b2fff4, Web Map',\n",
       "  'Citizen Problem Explorer, Item ID: 9d77d6608c6b4ae5a9be638df2b2fff4, Web Map',\n",
       "  'Citizen Problem Explorer, Item ID: 9d77d6608c6b4ae5a9be638df2b2fff4, Web Map'],\n",
       " 'PSN Drug Dashboard': ['PSN Drug Map, Item ID: 64afed194a634e689665b2c998566cf8, Web Map'],\n",
       " 'Capital Project Mobile Dashboard': ['Capital Project Dashboard, Item ID: 1157014d0e5e476a891052f2e4b57ce4, Web Map'],\n",
       " 'City of Billings - Traffic Counts': ['Traffic Count, Item ID: b1150ae483784827ba0bbd4b40c9ffc0, Web Map'],\n",
       " 'Billings MPO LRTP Projects Dashboard Map': ['Billings MPO LRTP Projects Dashboard Map, Item ID: 87767048e20c48328d7174baad1a51ad, Web Map',\n",
       "  'Billings MPO LRTP Projects Dashboard Map, Item ID: 87767048e20c48328d7174baad1a51ad, Web Map',\n",
       "  'Billings MPO LRTP Projects Dashboard Map, Item ID: 87767048e20c48328d7174baad1a51ad, Web Map',\n",
       "  'Billings MPO LRTP Projects Dashboard Map, Item ID: 87767048e20c48328d7174baad1a51ad, Web Map',\n",
       "  'Billings MPO LRTP Projects Dashboard Map, Item ID: 87767048e20c48328d7174baad1a51ad, Web Map',\n",
       "  'Billings MPO LRTP Projects Dashboard Map, Item ID: 87767048e20c48328d7174baad1a51ad, Web Map',\n",
       "  'Billings MPO LRTP Projects Dashboard Map, Item ID: 87767048e20c48328d7174baad1a51ad, Web Map',\n",
       "  'Billings MPO LRTP Projects Dashboard Map, Item ID: 87767048e20c48328d7174baad1a51ad, Web Map',\n",
       "  'Billings MPO LRTP Projects Dashboard Map, Item ID: 87767048e20c48328d7174baad1a51ad, Web Map',\n",
       "  'Billings MPO LRTP Projects Dashboard Map, Item ID: 87767048e20c48328d7174baad1a51ad, Web Map',\n",
       "  'Billings MPO LRTP Projects Dashboard Map, Item ID: 87767048e20c48328d7174baad1a51ad, Web Map'],\n",
       " 'Tree Request Dashboard': ['Tree Request Dashboard, Item ID: 78208d72880a451b897133506d6f253a, Web Map',\n",
       "  'Tree Request Dashboard, Item ID: 78208d72880a451b897133506d6f253a, Web Map',\n",
       "  'Tree Request Dashboard, Item ID: 78208d72880a451b897133506d6f253a, Web Map',\n",
       "  'Tree Request Dashboard, Item ID: 78208d72880a451b897133506d6f253a, Web Map',\n",
       "  'Tree Request Dashboard, Item ID: 78208d72880a451b897133506d6f253a, Web Map',\n",
       "  'Tree Request Dashboard, Item ID: 78208d72880a451b897133506d6f253a, Web Map',\n",
       "  'Tree Request Dashboard, Item ID: 78208d72880a451b897133506d6f253a, Web Map'],\n",
       " 'Planting Areas Dashboard': ['Planting Areas Dashboard, Item ID: dae94d6fa3c6476480f7e8cd747d51ec, Web Map',\n",
       "  'Planting Areas Dashboard, Item ID: dae94d6fa3c6476480f7e8cd747d51ec, Web Map',\n",
       "  'Planting Areas Dashboard, Item ID: dae94d6fa3c6476480f7e8cd747d51ec, Web Map',\n",
       "  'Planting Areas Dashboard, Item ID: dae94d6fa3c6476480f7e8cd747d51ec, Web Map',\n",
       "  'Planting Areas Dashboard, Item ID: dae94d6fa3c6476480f7e8cd747d51ec, Web Map',\n",
       "  'Planting Areas Dashboard, Item ID: dae94d6fa3c6476480f7e8cd747d51ec, Web Map',\n",
       "  'Planting Areas Dashboard, Item ID: dae94d6fa3c6476480f7e8cd747d51ec, Web Map',\n",
       "  'Planting Areas Dashboard, Item ID: dae94d6fa3c6476480f7e8cd747d51ec, Web Map',\n",
       "  'Planting Areas Dashboard, Item ID: dae94d6fa3c6476480f7e8cd747d51ec, Web Map',\n",
       "  'Planting Areas Dashboard, Item ID: dae94d6fa3c6476480f7e8cd747d51ec, Web Map',\n",
       "  'Planting Areas Dashboard, Item ID: dae94d6fa3c6476480f7e8cd747d51ec, Web Map',\n",
       "  'Planting Areas Dashboard, Item ID: dae94d6fa3c6476480f7e8cd747d51ec, Web Map',\n",
       "  'Planting Areas Dashboard, Item ID: dae94d6fa3c6476480f7e8cd747d51ec, Web Map',\n",
       "  'Planting Areas Dashboard, Item ID: dae94d6fa3c6476480f7e8cd747d51ec, Web Map',\n",
       "  'Planting Areas Dashboard, Item ID: dae94d6fa3c6476480f7e8cd747d51ec, Web Map',\n",
       "  'Planting Areas Dashboard, Item ID: dae94d6fa3c6476480f7e8cd747d51ec, Web Map',\n",
       "  'Planting Areas Dashboard, Item ID: dae94d6fa3c6476480f7e8cd747d51ec, Web Map']}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dashboard_map_dependency_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2888d61b-e3de-405c-af50-2835471e773e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See analogous experience code for notes\n",
    "\n",
    "dash_dependency_dict = {}\n",
    "for key in dashboard_map_dependency_dict: #Looping over experiences\n",
    "    inner_dict = {}\n",
    "\n",
    "    try:\n",
    "        for webmapval in dashboard_map_dependency_dict[key]: #Looping over webmaps corresponding to each experience\n",
    "            innermost_dict = {}\n",
    "            match = re.search(r'ID:\\s*([\\w]+)', webmapval, re.IGNORECASE) #Uses regex matching to extract webmap itemid from the dictionary value.\n",
    "            idtext = match.group(1)\n",
    "            mapItem = gis.content.get(idtext) #Finds webmap associated with the id value\n",
    "            dependencies = mapItem.dependent_upon()['list'] #returns a dictionary with details on supporting services. try_json is optional but may help convert the data to a dictionary.              \n",
    "            dep_info_list = dependency_recursion(dependencies) #Pulls supporting services out of dependency JSON and adds to list\n",
    "\n",
    "            for each in dep_info_list: #Looping through the services associated with a single web map\n",
    "                match_found = False\n",
    "                for x, y in fc_dict.items(): \n",
    "                    if x in each:\n",
    "                        innermost_dict[each] = y\n",
    "                        match_found = True\n",
    "                        break\n",
    "                if not match_found:\n",
    "                    innermost_dict[each] = [\"This Service is Hosted on AGOL or is a Raster Image\"]\n",
    "                                                                            \n",
    "            inner_dict[f\"{mapItem.title}, Item ID: {mapItem.id}\"] = innermost_dict\n",
    "            \n",
    "        dash_dependency_dict[key] = inner_dict #writes keys and values to empty dictionary.\n",
    "    except Exception as e:\n",
    "        print(f'{key} {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "739a2684-6b2b-4556-8c1b-2b18113db4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dash_service_dict = {}\n",
    "temp_dash_service_dict = {}\n",
    "final_dash_service_dict = {}\n",
    "\n",
    "for dash, webmap in dash_dependency_dict.items():\n",
    "    for wmap, service in webmap.items():\n",
    "        dash_service_dict[dash] = service\n",
    "\n",
    "for dash, service, in dashboard_service_dependency_dict.items():\n",
    "    for serv in service:\n",
    "        temp_dash_service_dict[dash] = {serv : ['This Service is Hosted on AGOL or is a Raster Image']}\n",
    "\n",
    "for dashboard, service in dash_service_dict.items():\n",
    "    final_dash_service_dict[dashboard] = service\n",
    "    for dash, serv in temp_dash_service_dict.items():\n",
    "        if dash not in final_dash_service_dict.keys():\n",
    "            final_dash_service_dict[dash] = serv\n",
    "\n",
    "            \n",
    "for dashboard, service in dash_service_dict.items():\n",
    "    final_dash_service_dict[dashboard] = service\n",
    "    for dash, serv in temp_dash_service_dict.items():        \n",
    "        if dashboard == dash:\n",
    "            service.update(serv)       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "22d40b7e-3cb7-4002-ac09-20f4f11c31ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of dependency matrix pandas dataframe from dependency dicts\n",
    "\n",
    "empty_df = pd.DataFrame(dtype = \"object\") #dtype must be object to avoid errors\n",
    "\n",
    "# for every service and fc, creates an index value if not seen before and creates an \"x\" at their intersection. If seen, just creates \"x\" at intersection.\n",
    "for webmap, service in map_dependency_dict.items(): \n",
    "    if service:\n",
    "        for serv, fc in service.items():\n",
    "            empty_df.loc[serv, fc] = \"x\" \n",
    "empty_df = empty_df.replace(b\"\", np.nan) #removes blank anomalies\n",
    "serv_fc_df = empty_df.copy() #consolidates the cells within memory\n",
    "serv_fc_df_t = serv_fc_df.transpose()\n",
    "\n",
    "\n",
    "\n",
    "empty_df = pd.DataFrame(dtype = \"object\")\n",
    "\n",
    "for webmap, service in map_dependency_dict.items():\n",
    "    if service:\n",
    "        for serv, fc in service.items():\n",
    "            empty_df.loc[webmap, fc] = \"x\"        \n",
    "empty_df = empty_df.replace(b\"\", np.nan)\n",
    "map_fc_df = empty_df.copy()\n",
    "map_fc_df_t = map_fc_df.transpose()\n",
    "\n",
    "\n",
    "\n",
    "empty_df = pd.DataFrame(dtype = \"object\")\n",
    "\n",
    "for exp, webmap in exp_dependency_dict.items():\n",
    "    if webmap:\n",
    "        for wmap, service in webmap.items():\n",
    "            for serv, fc in service.items():\n",
    "                empty_df.loc[exp, fc] = \"x\"        \n",
    "empty_df = empty_df.replace(b\"\", np.nan)\n",
    "exp_fc_df = empty_df.copy()\n",
    "exp_fc_df_t = exp_fc_df.transpose()\n",
    "\n",
    "empty_df = pd.DataFrame(dtype = \"object\")\n",
    "\n",
    "for dash, webmap in dash_dependency_dict.items():\n",
    "    for wmap, service in webmap.items():\n",
    "        for serv, fc in service.items():\n",
    "            empty_df.loc[dash, fc] = \"x\"        \n",
    "empty_df = empty_df.replace(b\"\", np.nan)\n",
    "dash_fc_df = empty_df.copy()\n",
    "dash_fc_df_t = dash_fc_df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6f78a162-f5ae-4808-8c5d-3e5c6a3fbf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(fr\"\\\\PWU-W12k07\\GIS_Files\\Tutorials\\Dependencies\\AGOL_Dependencies_{formatted_date_mdy}\\Feature Class Dependencies.xlsx\", \n",
    "    engine='xlsxwriter')\n",
    "\n",
    "sheet1 = create_new_sheet(writer, serv_fc_df, \"Services by FC\", \"Services\")\n",
    "sheet2 = create_new_sheet(writer, serv_fc_df_t, \"FCs by Services\", \"Feature Classes\")\n",
    "sheet3 = create_new_sheet(writer, map_fc_df, \"Webmaps by FC\", \"Webmaps\")\n",
    "sheet4 = create_new_sheet(writer, map_fc_df_t, \"FCs by Webmap\", \"Feature Classes\")\n",
    "sheet5 = create_new_sheet(writer, exp_fc_df, \"Experiences by FC\", \"Experiences\")\n",
    "sheet6 = create_new_sheet(writer, exp_fc_df_t, \"FCs by Experience\", \"Feature Classes\")\n",
    "sheet7 = create_new_sheet(writer, dash_fc_df, \"Dashboards by FC\", \"Experiences\")\n",
    "sheet8 = create_new_sheet(writer, dash_fc_df_t, \"FCs by Dashboard\", \"Feature Classes\")\n",
    "\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e483756e-5874-4266-8315-4003d4b7da8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n",
      "C:\\Users\\norellp\\AppData\\Local\\Temp\\ipykernel_27196\\2159096078.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  empty_df.loc[webmap, serv] = \"x\"\n"
     ]
    }
   ],
   "source": [
    "empty_df = pd.DataFrame(dtype = \"object\")\n",
    "\n",
    "for webmap, service in map_dependency_dict.items():\n",
    "    if service:\n",
    "        for serv, fc in service.items():\n",
    "            empty_df.loc[webmap, serv] = \"x\"\n",
    "empty_df = empty_df.replace(b\"\", np.nan)\n",
    "map_serv_df = empty_df.copy()\n",
    "map_serv_df_t = map_serv_df.transpose()\n",
    "\n",
    "\n",
    "empty_df = pd.DataFrame(dtype = \"object\")\n",
    "\n",
    "for exp, webmap in exp_dependency_dict.items():\n",
    "    if webmap:\n",
    "        for wmap, service in webmap.items():\n",
    "            if service:\n",
    "                for serv, fc in service.items():\n",
    "                    empty_df.loc[exp, serv] = \"x\"        \n",
    "empty_df = empty_df.replace(b\"\", np.nan)\n",
    "exp_serv_df = empty_df.copy()\n",
    "exp_serv_df_t = exp_serv_df.transpose()\n",
    "\n",
    "empty_df = pd.DataFrame(dtype = \"object\")\n",
    "\n",
    "for dash, service in final_dash_service_dict.items():\n",
    "    for serv, fc in service.items():\n",
    "            empty_df.loc[dash, serv] = \"x\"        \n",
    "empty_df = empty_df.replace(b\"\", np.nan)\n",
    "dash_serv_df = empty_df.copy()\n",
    "dash_serv_df_t = dash_serv_df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "70e16232-07f6-4b24-ae93-4b3b2ca0f603",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(fr\"\\\\PWU-W12k07\\GIS_Files\\Tutorials\\Dependencies\\AGOL_Dependencies_{formatted_date_mdy}\\Feature Service Dependencies.xlsx\", \n",
    "    engine='xlsxwriter')\n",
    "\n",
    "sheet1 = create_new_sheet(writer, map_serv_df, \"Webmaps by Service\", \"Webmaps\")\n",
    "sheet2 = create_new_sheet(writer, map_serv_df_t, \"Services by Webmap\", \"Services\")\n",
    "sheet3 = create_new_sheet(writer, exp_serv_df, \"Experiences by Service\", \"Experiences\")\n",
    "sheet4 = create_new_sheet(writer, exp_serv_df_t, \"Services by Experience\", \"Services\")\n",
    "sheet5 = create_new_sheet(writer, dash_serv_df, \"Dashboards by Service\", \"Dashboards\")\n",
    "sheet6 = create_new_sheet(writer, dash_serv_df_t, \"Services by Dashboard\", \"Services\")\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ffe9bf2a-2805-4514-b805-45d023eb84c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_df = pd.DataFrame(dtype = \"object\")\n",
    "\n",
    "for exp, webmap in exp_dependency_dict.items():\n",
    "    if webmap:\n",
    "        for wmap, service in webmap.items():\n",
    "            empty_df.loc[exp, wmap] = \"x\"        \n",
    "empty_df = empty_df.replace(b\"\", np.nan)\n",
    "exp_map_df = empty_df.copy()\n",
    "exp_map_df_t = exp_map_df.transpose()\n",
    "\n",
    "empty_df = pd.DataFrame(dtype = \"object\")\n",
    "\n",
    "for dash, webmap in dash_dependency_dict.items():\n",
    "    for wmap, service in webmap.items():\n",
    "            empty_df.loc[dash, wmap] = \"x\"        \n",
    "empty_df = empty_df.replace(b\"\", np.nan)\n",
    "dash_map_df = empty_df.copy()\n",
    "dash_map_df_t = dash_map_df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e6c143e1-5b2d-43ae-983e-3d36ff2eb5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(fr\"\\\\PWU-W12k07\\GIS_Files\\Tutorials\\Dependencies\\AGOL_Dependencies_{formatted_date_mdy}\\Webmap Dependencies.xlsx\", \n",
    "    engine='xlsxwriter')\n",
    "\n",
    "sheet1 = create_new_sheet(writer, exp_map_df, \"Experiences by Webmap\", \"Experiences\")\n",
    "sheet2 = create_new_sheet(writer, exp_map_df_t, \"Webmaps by Experience\", \"Webmaps\")\n",
    "sheet3 = create_new_sheet(writer, dash_map_df, \"Dashboards by Webmap\", \"Dashboards\")\n",
    "sheet4 = create_new_sheet(writer, dash_map_df_t, \"Webmaps by Dashboards\", \"Webmaps\")\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9a116044-51d1-4fa6-a352-0d73e2dd97dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a an Excel sheet showing feature, map, and vector tile services that are not consumed by webmaps, experiences, or dashboards.\n",
    "\n",
    "orphan_services = [] \n",
    "temp_orphan_list = []\n",
    "duplicate_list =[]\n",
    "duplicate_list2 = []\n",
    "for each in servid: # Ruling out services consumed by webmaps.\n",
    "   if all(each not in serv for webmap, service in map_dependency_dict.items() for serv, fc in service.items()):\n",
    "        duplicate_list.append(each)\n",
    "\n",
    "for each in duplicate_list: # Ruling out services that aren't consumed by webmaps but are consumed by dashbaords.\n",
    "    if all(each not in serv for dashboard, service in dashboard_service_dependency_dict.items() for serv in service):\n",
    "        duplicate_list2.append(each)\n",
    "        \n",
    "for each in duplicate_list2: # Removes duplicates.\n",
    "    if each not in orphan_services:\n",
    "        temp_orphan_list.append(each)\n",
    "        \n",
    "for each in services_list:\n",
    "    if any(servid in each for servid in temp_orphan_list):\n",
    "        if \"cityworks\" not in each.lower():\n",
    "            orphan_services.append(each)  \n",
    "\n",
    "orphan_df = pd.DataFrame(orphan_services)\n",
    "\n",
    "writer = pd.ExcelWriter(fr\"\\\\PWU-W12k07\\GIS_Files\\Tutorials\\Dependencies\\AGOL_Dependencies_{formatted_date_mdy}\\Orphan Services.xlsx\", \n",
    "    engine='xlsxwriter')\n",
    "orphan_df.to_excel(writer, sheet_name = \"Sheet_1\")\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b8ac9e-1ee0-460d-857d-9c2494b47908",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
